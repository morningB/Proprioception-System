{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Best Score: 0.6390476190476191\n",
      "Confusion Matrix:\n",
      "[[28  8]\n",
      " [ 6 30]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       close       0.82      0.78      0.80        36\n",
      "        open       0.79      0.83      0.81        36\n",
      "\n",
      "    accuracy                           0.81        72\n",
      "   macro avg       0.81      0.81      0.81        72\n",
      "weighted avg       0.81      0.81      0.81        72\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yjw00\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "1800 fits failed out of a total of 3600.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1042 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\yjw00\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\yjw00\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\yjw00\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\yjw00\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "158 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\yjw00\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\yjw00\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\yjw00\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\yjw00\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "600 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\yjw00\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\yjw00\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\yjw00\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\yjw00\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\yjw00\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.58095238 0.55428571\n",
      " 0.56761905 0.58190476 0.51142857 0.58190476 0.56857143 0.56857143\n",
      " 0.59619048 0.59714286 0.61047619 0.58285714        nan        nan\n",
      "        nan        nan 0.58095238 0.61047619 0.61047619 0.59619048\n",
      " 0.58285714 0.61047619 0.61047619 0.61047619 0.61047619 0.63904762\n",
      " 0.59619048 0.61047619        nan        nan        nan        nan\n",
      " 0.61047619 0.63619048 0.62285714 0.63714286 0.61047619 0.63619048\n",
      " 0.62285714 0.63714286 0.61142857 0.6247619  0.63714286 0.63714286\n",
      "        nan        nan        nan        nan 0.58095238 0.55428571\n",
      " 0.56761905 0.58190476 0.51142857 0.58190476 0.56857143 0.56857143\n",
      " 0.59619048 0.59714286 0.61047619 0.58285714        nan        nan\n",
      "        nan        nan 0.58095238 0.61047619 0.61047619 0.59619048\n",
      " 0.58285714 0.61047619 0.61047619 0.61047619 0.61047619 0.63904762\n",
      " 0.59619048 0.61047619        nan        nan        nan        nan\n",
      " 0.61047619 0.63619048 0.62285714 0.63714286 0.61047619 0.63619048\n",
      " 0.62285714 0.63714286 0.61142857 0.6247619  0.63714286 0.63714286\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.58095238 0.55428571\n",
      " 0.56761905 0.58190476 0.51142857 0.58190476 0.56857143 0.56857143\n",
      " 0.59619048 0.59714286 0.61047619 0.59619048        nan        nan\n",
      "        nan        nan 0.58095238 0.61047619 0.61047619 0.59619048\n",
      " 0.58285714 0.61047619 0.61047619 0.61047619 0.61047619 0.63904762\n",
      " 0.59619048 0.61047619        nan        nan        nan        nan\n",
      " 0.61047619 0.63619048 0.62285714 0.63714286 0.61047619 0.63619048\n",
      " 0.62285714 0.63714286 0.61142857 0.6247619  0.63714286 0.63714286\n",
      "        nan        nan        nan        nan 0.58095238 0.55428571\n",
      " 0.56761905 0.58190476 0.51142857 0.58190476 0.56857143 0.56857143\n",
      " 0.59619048 0.59714286 0.61047619 0.59619048        nan        nan\n",
      "        nan        nan 0.58095238 0.61047619 0.61047619 0.59619048\n",
      " 0.58285714 0.61047619 0.61047619 0.61047619 0.61047619 0.63904762\n",
      " 0.59619048 0.61047619        nan        nan        nan        nan\n",
      " 0.61047619 0.63619048 0.62285714 0.63714286 0.61047619 0.63619048\n",
      " 0.62285714 0.63714286 0.61142857 0.6247619  0.63714286 0.63714286\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.58095238 0.55428571\n",
      " 0.56761905 0.58190476 0.51142857 0.58190476 0.56857143 0.56857143\n",
      " 0.59619048 0.59714286 0.61047619 0.58285714        nan        nan\n",
      "        nan        nan 0.58095238 0.61047619 0.61047619 0.59619048\n",
      " 0.58285714 0.61047619 0.61047619 0.61047619 0.61047619 0.63904762\n",
      " 0.59619048 0.61047619        nan        nan        nan        nan\n",
      " 0.61047619 0.63619048 0.62285714 0.63714286 0.61047619 0.63619048\n",
      " 0.62285714 0.63714286 0.61142857 0.6247619  0.63714286 0.63714286\n",
      "        nan        nan        nan        nan 0.58095238 0.55428571\n",
      " 0.56761905 0.58190476 0.51142857 0.58190476 0.56857143 0.56857143\n",
      " 0.59619048 0.59714286 0.61047619 0.58285714        nan        nan\n",
      "        nan        nan 0.58095238 0.61047619 0.61047619 0.59619048\n",
      " 0.58285714 0.61047619 0.61047619 0.61047619 0.61047619 0.63904762\n",
      " 0.59619048 0.61047619        nan        nan        nan        nan\n",
      " 0.61047619 0.63619048 0.62285714 0.63714286 0.61047619 0.63619048\n",
      " 0.62285714 0.63714286 0.61142857 0.6247619  0.63714286 0.63714286\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.58095238 0.55428571\n",
      " 0.56761905 0.58190476 0.51142857 0.58190476 0.56857143 0.56857143\n",
      " 0.59619048 0.59714286 0.61047619 0.58285714        nan        nan\n",
      "        nan        nan 0.58095238 0.61047619 0.61047619 0.59619048\n",
      " 0.58285714 0.61047619 0.61047619 0.61047619 0.61047619 0.63904762\n",
      " 0.59619048 0.61047619        nan        nan        nan        nan\n",
      " 0.61047619 0.63619048 0.62285714 0.63714286 0.61047619 0.63619048\n",
      " 0.62285714 0.63714286 0.61142857 0.6247619  0.63714286 0.63714286\n",
      "        nan        nan        nan        nan 0.58095238 0.55428571\n",
      " 0.56761905 0.58190476 0.51142857 0.58190476 0.56857143 0.56857143\n",
      " 0.59619048 0.59714286 0.61047619 0.58285714        nan        nan\n",
      "        nan        nan 0.58095238 0.61047619 0.61047619 0.59619048\n",
      " 0.58285714 0.61047619 0.61047619 0.61047619 0.61047619 0.63904762\n",
      " 0.59619048 0.61047619        nan        nan        nan        nan\n",
      " 0.61047619 0.63619048 0.62285714 0.63714286 0.61047619 0.63619048\n",
      " 0.62285714 0.63714286 0.61142857 0.6247619  0.63714286 0.63714286\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.58095238 0.55428571\n",
      " 0.56761905 0.58190476 0.51142857 0.58190476 0.56857143 0.56857143\n",
      " 0.59619048 0.59714286 0.61047619 0.58285714        nan        nan\n",
      "        nan        nan 0.58095238 0.61047619 0.61047619 0.59619048\n",
      " 0.58285714 0.61047619 0.61047619 0.61047619 0.61047619 0.63904762\n",
      " 0.59619048 0.61047619        nan        nan        nan        nan\n",
      " 0.61047619 0.63619048 0.62285714 0.63714286 0.61047619 0.63619048\n",
      " 0.62285714 0.63714286 0.61142857 0.6247619  0.63714286 0.63714286\n",
      "        nan        nan        nan        nan 0.58095238 0.55428571\n",
      " 0.56761905 0.58190476 0.51142857 0.58190476 0.56857143 0.56857143\n",
      " 0.59619048 0.59714286 0.61047619 0.58285714        nan        nan\n",
      "        nan        nan 0.58095238 0.61047619 0.61047619 0.59619048\n",
      " 0.58285714 0.61047619 0.61047619 0.61047619 0.61047619 0.63904762\n",
      " 0.59619048 0.61047619        nan        nan        nan        nan\n",
      " 0.61047619 0.63619048 0.62285714 0.63714286 0.61047619 0.63619048\n",
      " 0.62285714 0.63714286 0.61142857 0.6247619  0.63714286 0.63714286]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 데이터 로드\n",
    "data = pd.read_csv('af.csv')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 특성과 타겟 변수 설정\n",
    "# X = df[['eyeOpen']]\n",
    "X = df[['e3','e4']]\n",
    "y = df['state3']\n",
    "\n",
    "# 레이블 인코딩\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# 특징 표준화\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Grid Search를 위한 파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],            # 나무의 개수\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],      # 각 나무에서 고려할 특성의 수\n",
    "    'max_depth': [None, 10, 20, 30, 40],           # 나무의 최대 깊이\n",
    "    'min_samples_split': [1, 2, 5, 10],                # 내부 노드를 분할하는 데 필요한 최소 샘플 수\n",
    "    'min_samples_leaf': [1, 2, 4]                   # 리프 노드에서의 최소 샘플 수\n",
    "}\n",
    "\n",
    "# Grid Search 초기화\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Grid Search 적합\n",
    "grid_search.fit(X_scaled, y_encoded)\n",
    "\n",
    "# Grid Search에서 가장 좋은 모델 가져오기\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 최적의 파라미터와 점수 출력\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# 최적 모델을 사용하여 예측\n",
    "y_pred = best_model.predict(X_scaled)\n",
    "\n",
    "# 예측된 레이블을 원래 레이블로 변환\n",
    "y_pred_labels = le.inverse_transform(y_pred)\n",
    "y_true_labels = le.inverse_transform(y_encoded)\n",
    "\n",
    "# 모델 평가\n",
    "conf_matrix = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true_labels, y_pred_labels))\n",
    "\n",
    "# # 혼동 행렬 시각화\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "#             xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "# plt.xlabel('예측 레이블')\n",
    "# plt.ylabel('실제 레이블')\n",
    "# plt.title('혼동 행렬')\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
